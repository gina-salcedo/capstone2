{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Factors affecting drinking in highschool students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data info:\n",
    "The data set was collected in Portugal for students of two schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Loaded Portuguese Class Data - Math Class only added 13 unique data points, which isn't very much out of almost 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Capstone Project/student-portuguese.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#other libraries and stats models to import - having all of them in a single place makes it easier to track\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.neighbors as knn\n",
    "import sklearn.datasets as ds\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.neighbors as knn\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Look for any obvious gaps, missing data, or outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school        649\n",
      "sex           649\n",
      "age           649\n",
      "address       649\n",
      "famsize       649\n",
      "Pstatus       649\n",
      "Medu          649\n",
      "Fedu          649\n",
      "Mjob          649\n",
      "Fjob          649\n",
      "reason        649\n",
      "guardian      649\n",
      "traveltime    649\n",
      "studytime     649\n",
      "failures      649\n",
      "schoolsup     649\n",
      "famsup        649\n",
      "paid          649\n",
      "activities    649\n",
      "nursery       649\n",
      "higher        649\n",
      "internet      649\n",
      "romantic      649\n",
      "famrel        649\n",
      "freetime      649\n",
      "goout         649\n",
      "Dalc          649\n",
      "Walc          649\n",
      "health        649\n",
      "absences      649\n",
      "G1            649\n",
      "G2            649\n",
      "G3            649\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checked data completeness - looks like there are no nulls\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 5 3 4]\n",
      "[1 3 2 4 5]\n"
     ]
    }
   ],
   "source": [
    "#checking unique answers for drinking levels questions - was curioius if there would be any zeros\n",
    "\n",
    "print(df['Dalc'].unique())\n",
    "print(df['Walc'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alcohol Counsumption Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### See what the counts look like for the alcohol-related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Walc_count']=df.groupby('Walc').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Dalc_count']=df.groupby('Dalc').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "plt.hist(x=df['Dalc'],bins=5, color='green', data=df['Dalc_count'])\n",
    "plt.xlabel('Level of Weekday Drinking')\n",
    "plt.ylabel('Total Students')\n",
    "plt.title('Weekday Drinking Response Distribution')\n",
    "plt.axis([1,5,1,450])\n",
    "plt.grid\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#plt.hist(x=df['Walc'],bins=5, color='blue', data=df['Walc_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "plt.hist(x=df['Walc'],bins=5, color='blue', data=df['Walc_count'])\n",
    "plt.xlabel('Level of Weekend Drinking')\n",
    "plt.ylabel('Total Students')\n",
    "plt.title('Weekend Drinking Response Distribution')\n",
    "plt.axis([1,5,1,450])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#plt.hist(x=df['Walc'],bins=5, color='blue', data=df['Walc_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Created a variable that unifies weekday and weekend drinking, alc\n",
    "\n",
    "df['alc']=df['Dalc']+df['Walc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alc\n",
       "2     241\n",
       "3     116\n",
       "4      99\n",
       "5      73\n",
       "6      50\n",
       "7      32\n",
       "8      17\n",
       "9       6\n",
       "10     15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('alc').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['alc_count']=df.groupby('alc').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "plt.hist(x=df['Walc'],bins=5, color='red', data=df['Walc_count'])\n",
    "plt.xlabel('Weekend and Weekday Drinking')\n",
    "plt.ylabel('Total Students')\n",
    "plt.title('Weekend + Weekday Drinking Response Distribution')\n",
    "plt.axis([1,5,1,450])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Due to the fact that 20, 21, and 22 year-olds have 6, 2, and 1 student respectively, I will drop all three to avoid skewing the data due to factors relating to age that I can't easily account for, so I am going to filter out all ages where len(age) is less than or equal to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.groupby('age').filter(lambda x: len(x)>20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "15    112\n",
       "16    177\n",
       "17    179\n",
       "18    140\n",
       "19     32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify that the dataset now looks as I expect - only ages 15-19\n",
    "\n",
    "df.groupby('age').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "15    112\n",
       "16    177\n",
       "17    179\n",
       "18    140\n",
       "19     32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('age').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTCOME: \n",
    "Only G1 (one of three sets of grades) is normal. Will stay away from models that require a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "age: \n",
      "Normal Test: 2.9739239935981005e-18\n",
      "[]\n",
      "failures: \n",
      "Normal Test: 2.550076851541849e-99\n",
      "[]\n",
      "absences: \n",
      "Normal Test: 3.8536119152460206e-64\n",
      "['G1']\n",
      "G1: \n",
      "Normal Test: 0.9226859823253339\n",
      "['G1']\n",
      "G2: \n",
      "Normal Test: 1.7906402177497228e-09\n",
      "['G1']\n",
      "G3: \n",
      "Normal Test: 1.5181025716180042e-25\n"
     ]
    }
   ],
   "source": [
    "normal=[]\n",
    "\n",
    "mylistnotcategorical= ['age','failures','absences', 'G1', 'G2', 'G3']\n",
    "\n",
    "for var in mylistnotcategorical:\n",
    "    if stats.normaltest(df[var]).pvalue > 0.5:\n",
    "        normal.append(var)\n",
    "    print(normal)\n",
    "    print(var + \": \" + '\\nNormal Test: {}'.format(stats.normaltest(df[var]).pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Created a graph to view the distributions more visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using qt5 instead.\n"
     ]
    }
   ],
   "source": [
    "mylistnotcategorical= ['age','failures','absences', 'G1', 'G2', 'G3']\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "for var in mylistnotcategorical:\n",
    "    df[var].plot(kind='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using qt5 instead.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "df.boxplot(column='Dalc', by='age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Weekday Drinking')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using qt5 instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x143102d0>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "df.boxplot(column='Dalc', by='Pstatus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using qt5 instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x146ad650>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "df.boxplot(column='Walc', by='Pstatus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Walc\n",
       "1    244\n",
       "2    148\n",
       "3    119\n",
       "4     85\n",
       "5     44\n",
       "Name: Pstatus, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Walc')['Pstatus'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age       \n",
       "15   count    112.000000\n",
       "     mean       1.383929\n",
       "     std        0.725911\n",
       "     min        1.000000\n",
       "     25%        1.000000\n",
       "     50%        1.000000\n",
       "     75%        2.000000\n",
       "     max        5.000000\n",
       "16   count    177.000000\n",
       "     mean       1.395480\n",
       "     std        0.798850\n",
       "     min        1.000000\n",
       "     25%        1.000000\n",
       "     50%        1.000000\n",
       "     75%        2.000000\n",
       "     max        5.000000\n",
       "17   count    179.000000\n",
       "     mean       1.553073\n",
       "     std        0.960588\n",
       "     min        1.000000\n",
       "     25%        1.000000\n",
       "     50%        1.000000\n",
       "     75%        2.000000\n",
       "     max        5.000000\n",
       "18   count    140.000000\n",
       "     mean       1.564286\n",
       "     std        1.026349\n",
       "     min        1.000000\n",
       "     25%        1.000000\n",
       "     50%        1.000000\n",
       "     75%        2.000000\n",
       "     max        5.000000\n",
       "19   count     32.000000\n",
       "     mean       1.781250\n",
       "     std        1.128355\n",
       "     min        1.000000\n",
       "     25%        1.000000\n",
       "     50%        1.000000\n",
       "     75%        3.000000\n",
       "     max        4.000000\n",
       "Name: Dalc, dtype: float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('age')['Dalc'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alc makes sense since it's the overall drinking indicator. I want to see if weekend and weekday drinking are different. It's also easier for some models to work with five categories instead of 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create dummies and remove original variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school         object\n",
       "sex            object\n",
       "age             int64\n",
       "address        object\n",
       "famsize        object\n",
       "Pstatus        object\n",
       "Medu            int64\n",
       "Fedu            int64\n",
       "Mjob           object\n",
       "Fjob           object\n",
       "reason         object\n",
       "guardian       object\n",
       "traveltime      int64\n",
       "studytime       int64\n",
       "failures        int64\n",
       "schoolsup      object\n",
       "famsup         object\n",
       "paid           object\n",
       "activities     object\n",
       "nursery        object\n",
       "higher         object\n",
       "internet       object\n",
       "romantic       object\n",
       "famrel          int64\n",
       "freetime        int64\n",
       "goout           int64\n",
       "Dalc            int64\n",
       "Walc            int64\n",
       "health          int64\n",
       "absences        int64\n",
       "G1              int64\n",
       "G2              int64\n",
       "G3              int64\n",
       "Walc_count    float64\n",
       "Dalc_count    float64\n",
       "alc             int64\n",
       "alc_count     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figure out variables with type object to create dummies\n",
    "\n",
    "df.dtypes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "needdummies = ['sex','address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian','schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'school']\n",
    "delfordummies=[]\n",
    "\n",
    "for var in needdummies:\n",
    "    df = pd.concat([df ,pd.get_dummies(df[var], drop_first =True, prefix = \"is_\" + var)], axis=1)\n",
    "    delfordummies.append(var)\n",
    "    del df[var]\n",
    "\n",
    "mylist=list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                       int64\n",
       "Medu                      int64\n",
       "Fedu                      int64\n",
       "traveltime                int64\n",
       "studytime                 int64\n",
       "failures                  int64\n",
       "famrel                    int64\n",
       "freetime                  int64\n",
       "goout                     int64\n",
       "Dalc                      int64\n",
       "Walc                      int64\n",
       "health                    int64\n",
       "absences                  int64\n",
       "G1                        int64\n",
       "G2                        int64\n",
       "G3                        int64\n",
       "Walc_count              float64\n",
       "Dalc_count              float64\n",
       "alc                       int64\n",
       "alc_count               float64\n",
       "is_sex_M                  uint8\n",
       "is_address_U              uint8\n",
       "is_famsize_LE3            uint8\n",
       "is_Pstatus_T              uint8\n",
       "is_Mjob_health            uint8\n",
       "is_Mjob_other             uint8\n",
       "is_Mjob_services          uint8\n",
       "is_Mjob_teacher           uint8\n",
       "is_Fjob_health            uint8\n",
       "is_Fjob_other             uint8\n",
       "is_Fjob_services          uint8\n",
       "is_Fjob_teacher           uint8\n",
       "is_reason_home            uint8\n",
       "is_reason_other           uint8\n",
       "is_reason_reputation      uint8\n",
       "is_guardian_mother        uint8\n",
       "is_guardian_other         uint8\n",
       "is_schoolsup_yes          uint8\n",
       "is_famsup_yes             uint8\n",
       "is_paid_yes               uint8\n",
       "is_activities_yes         uint8\n",
       "is_nursery_yes            uint8\n",
       "is_higher_yes             uint8\n",
       "is_internet_yes           uint8\n",
       "is_romantic_yes           uint8\n",
       "is_school_MS              uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify no object types left\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-181-2af4a0f45e64>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-181-2af4a0f45e64>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    print var, ':', df[var].unique()\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#want to see what the values look like\n",
    "\n",
    "for var in mylist:\n",
    "    print var, ':', df[var].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'health', 'absences', 'G1', 'G2', 'G3', 'Walc_count', 'Dalc_count', 'alc_count', 'is_sex_M', 'is_address_U', 'is_famsize_LE3', 'is_Pstatus_T', 'is_Mjob_health', 'is_Mjob_other', 'is_Mjob_services', 'is_Mjob_teacher', 'is_Fjob_health', 'is_Fjob_other', 'is_Fjob_services', 'is_Fjob_teacher', 'is_reason_home', 'is_reason_other', 'is_reason_reputation', 'is_guardian_mother', 'is_guardian_other', 'is_schoolsup_yes', 'is_famsup_yes', 'is_paid_yes', 'is_activities_yes', 'is_nursery_yes', 'is_higher_yes', 'is_internet_yes', 'is_romantic_yes', 'is_school_MS']\n"
     ]
    }
   ],
   "source": [
    "Xvars=list(df.columns.values)\n",
    "\n",
    "Xvars.remove('alc')\n",
    "Xvars.remove('Dalc')\n",
    "Xvars.remove('Walc')\n",
    "\n",
    "print(Xvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split my data set into train, validation, and test\n",
    "\n",
    "train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-184-d4a962f2c497>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-184-d4a962f2c497>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print 'train: ', train['age'].count()\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#printed out counts to make sure it worked\n",
    "\n",
    "print 'train: ', train['age'].count()\n",
    "print 'validate: ', validate['age'].count()\n",
    "print 'test: ', test['age'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scope1=['age','health', 'famrel','is_Pstatus_T', 'is_sex_M', 'failures',  'is_internet_yes', 'absences']\n",
    "\n",
    "scope2=['Medu', 'Fedu','is_famsup_yes', 'is_higher_yes', 'is_famsize_LE3', 'is_guardian_other']\n",
    "\n",
    "scope3=['is_reason_reputation', 'is_activities_yes', 'failures', 'absences', 'goout', 'is_romantic_yes', 'traveltime']\n",
    "\n",
    "scope4=['is_activities_yes', 'is_Pstatus_T', 'G1', 'is_internet_yes', 'failures']\n",
    "\n",
    "scope5=['age', 'is_sex_M', 'is_internet_yes', 'famrel', 'is_higher_yes']\n",
    "\n",
    "scope6=['age', 'failures', 'absences', 'is_higher_yes', 'is_nursery_yes', 'is_Mjob_health', 'is_Fjob_health']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried some groupings of factors that I would expect would relate to each other, to see if the score for the model was better that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Personal Relationships\n",
    "scope6=[ 'famrel', 'is_famsize_LE3', 'is_Pstatus_T', 'is_guardian_other', 'is_guardian_mother', 'is_famsup_yes', \n",
    "        'is_romantic_yes']\n",
    "\n",
    "#Allocation of time\n",
    "scope7=[ 'traveltime', 'studytime','freetime', 'absences',]\n",
    "\n",
    "#Educational Resources\n",
    "scope8=['absences','failures','is_reason_reputation','is_schoolsup_yes', 'is_famsup_yes', 'is_internet_yes',]\n",
    "\n",
    "#Motivation\n",
    "scope9=[ 'studytime','failures','absences', 'G1', 'G2', 'G3', 'is_activities_yes','is_higher_yes']\n",
    "\n",
    "#Socio-economic status\n",
    "scope10=[ 'Medu', 'Fedu', 'traveltime', 'is_address_U','is_reason_home', 'is_paid_yes', 'is_nursery_yes', \n",
    "         'is_internet_yes']\n",
    "\n",
    "#Personal identifying traits\n",
    "scope11=['age', 'health',  'is_sex_M', 'is_school_MS']\n",
    "\n",
    "#Emotional and Personal Support\n",
    "scope12=['famrel', 'goout','is_schoolsup_yes', 'is_famsup_yes','is_Pstatus_T']\n",
    "\n",
    "#Parental influence\n",
    "scope13=['is_Mjob_health', 'is_Mjob_other', 'is_Mjob_services','is_famsize_LE3', 'is_Pstatus_T', \n",
    "         'is_Mjob_teacher','is_Fjob_health','is_Fjob_other','is_Fjob_services','is_Fjob_teacher']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GridSearchCV(estimator= knn.KNeighborsClassifier(),\n",
    "                     cv=5,\n",
    "                     param_grid={'n_neighbors': range(1,10)}, \n",
    "                     scoring= 'accuracy')\n",
    "\n",
    "y=train['Dalc']\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    model.fit(train[X],y)\n",
    "    #print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['Dalc'] == 0) / float(len(train['Dalc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['Dalc'] == 0) / float(len(validate['Dalc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GridSearchCV(estimator= knn.KNeighborsClassifier(),\n",
    "                     cv=5,\n",
    "                     param_grid={'n_neighbors': range(1,10)}, \n",
    "                     scoring= 'accuracy')\n",
    "\n",
    "y=train['Walc']\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    model.fit(train[X],y)\n",
    "    #print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['Walc'] == 0) / float(len(train['Walc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['Walc'] == 0) / float(len(validate['Walc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GridSearchCV(estimator= knn.KNeighborsClassifier(),\n",
    "                     cv=5,\n",
    "                     param_grid={'n_neighbors': range(1,10)}, \n",
    "                     scoring= 'accuracy')\n",
    "\n",
    "y=train['alc']\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    model.fit(train[X],y)\n",
    "    #print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['alc'] == 0) / float(len(train['alc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['alc'] == 0) / float(len(validate['alc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### RamdomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scopelist=[scope1, scope2, scope3, scope4, scope5, scope6, scope7, scope8, scope9, scope10, scope11, scope12, scope13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=train['Dalc']\n",
    "\n",
    "model = ms.GridSearchCV(RandomForestClassifier(),\n",
    "                        param_grid={'n_estimators': [10, 100],\n",
    "                                    'min_samples_split': [50, 100]},\n",
    "                        cv=ms.StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0),\n",
    "                        scoring='neg_log_loss')\n",
    "\n",
    "modeldata=[]\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    model.fit(train[X],y)\n",
    "    print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['Dalc'] == 0) / float(len(train['Dalc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['Dalc'] == 0) / float(len(validate['Dalc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=train['Dalc']\n",
    "\n",
    "model = ms.GridSearchCV(RandomForestClassifier(),\n",
    "                        param_grid={'n_estimators': [10, 100],\n",
    "                                    'min_samples_split': [50, 100]},\n",
    "                        cv=ms.StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0),\n",
    "                        scoring='neg_log_loss')\n",
    "\n",
    "modeldata=[]\n",
    "\n",
    "#Used this code below to test the importance of features in multiple scopes and get a sense of what variables\n",
    "#Keep popping up. I created some scopes using those and re-ran the model to try and get the most predictive items\n",
    "\n",
    "X=scope10\n",
    "model.fit(train[X],y)\n",
    "    #print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "\n",
    "features = X\n",
    "feature_importances = model.best_estimator_.feature_importances_\n",
    "\n",
    "    \n",
    "features_df = pd.DataFrame({'Features': features, 'Importance Score': feature_importances})\n",
    "features_df.sort_values('Importance Score', inplace=True, ascending=False)\n",
    "\n",
    "features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# higher = more important\n",
    "\n",
    "for i in range(13):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=train['Walc']\n",
    "\n",
    "model = ms.GridSearchCV(RandomForestClassifier(),\n",
    "                        param_grid={'n_estimators': [10, 100],\n",
    "                                    'min_samples_split': [50, 100]},\n",
    "                        cv=ms.StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0),\n",
    "                        scoring='neg_log_loss')\n",
    "\n",
    "modeldata=[]\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    model.fit(train[X],y)\n",
    "    print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['Walc'] == 0) / float(len(train['Walc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['Walc'] == 0) / float(len(validate['Walc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=train['alc']\n",
    "\n",
    "model = ms.GridSearchCV(RandomForestClassifier(),\n",
    "                        param_grid={'n_estimators': [10, 100],\n",
    "                                    'min_samples_split': [50, 100]},\n",
    "                        cv=ms.StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0),\n",
    "                        scoring='neg_log_loss')\n",
    "\n",
    "modeldata=[]\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    model.fit(train[X],y)\n",
    "    print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['alc'] == 0) / float(len(train['alc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['alc'] == 0) / float(len(validate['alc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#model=ms.GridSearchCV(DecisionTreeClassifier(), \n",
    "      #                {'max_depth': range(2, 10,1), 'min_samples_leaf': range(5,25,5)},scoring='neg_log_loss')\n",
    "\n",
    "#tried using all variables\n",
    "model=DecisionTreeClassifier()\n",
    "model.fit(train[Xvars], train['Dalc'])\n",
    "\n",
    "acc = sum(model.predict(train[Xvars]) - train['Dalc'] == 0) / float(len(train['Dalc']))\n",
    "print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(validate[Xvars]) - validate['Dalc'] == 0) / float(len(validate['Dalc']))\n",
    "print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "\n",
    "\n",
    "#now trying with scope loop\n",
    "y=train['Dalc']\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    print X\n",
    "    model.fit(train[X],y)\n",
    "    #print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['Dalc'] == 0) / float(len(train['Dalc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['Dalc'] == 0) / float(len(validate['Dalc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Fits the model\n",
    "#model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model=ms.GridSearchCV(DecisionTreeClassifier(), \n",
    "                      {'max_depth': range(2, 10,1), 'min_samples_leaf': range(5,25,5)},scoring='neg_log_loss')\n",
    "\n",
    "#tried using all variables\n",
    "model.fit(train[scope4], train['Dalc'])\n",
    "\n",
    "acc = sum(model.predict(train[scope4]) - train['Dalc'] == 0) / float(len(train['Dalc']))\n",
    "print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(validate[scope4]) - validate['Dalc'] == 0) / float(len(validate['Dalc']))\n",
    "print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model=ms.GridSearchCV(DecisionTreeClassifier(), \n",
    "                      {'max_depth': range(2, 10,1), 'min_samples_leaf': range(5,25,5)},scoring='neg_log_loss')\n",
    "\n",
    "#tried using all variables\n",
    "model.fit(train[Xvars], train['Walc'])\n",
    "\n",
    "acc = sum(model.predict(train[Xvars]) - train['Walc'] == 0) / float(len(train['Walc']))\n",
    "print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(validate[Xvars]) - validate['Walc'] == 0) / float(len(validate['Walc']))\n",
    "print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "\n",
    "#now trying with scope loop\n",
    "y=train['Walc']\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    model.fit(train[X],y)\n",
    "    #print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['Walc'] == 0) / float(len(train['Walc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['Walc'] == 0) / float(len(validate['Walc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Fits the model\n",
    "#model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model=ms.GridSearchCV(DecisionTreeClassifier(), \n",
    "                      {'max_depth': range(2, 10,1), 'min_samples_leaf': range(5,25,5)},scoring='neg_log_loss')\n",
    "\n",
    "#tried using all variables\n",
    "model.fit(train[Xvars], train['Walc'])\n",
    "\n",
    "acc = sum(model.predict(train[Xvars]) - train['Walc'] == 0) / float(len(train['Walc']))\n",
    "print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(validate[Xvars]) - validate['Walc'] == 0) / float(len(validate['Walc']))\n",
    "print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "\n",
    "#now trying with scope loop\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    model.fit(train[X],y)\n",
    "    #print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['Walc'] == 0) / float(len(train['Walc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['Walc'] == 0) / float(len(validate['Walc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Fits the model\n",
    "#model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used entire dataset only - trying the scope values, the models were at 20% correcteness, which makes sense based on what this model is usually doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-3752f009d0df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mXvars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dalc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mXvars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dalc'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dalc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\gisalce\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\gisalce\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         X, y = check_X_y(X, y, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[0;32m--> 111\u001b[0;31m                          y_numeric=is_regressor(self))\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\gisalce\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32mC:\\Users\\gisalce\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\gisalce\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "model=AdaBoostClassifier()\n",
    "model.fit(train[Xvars], train['Dalc'])\n",
    "\n",
    "\n",
    "acc = sum(model.predict(train[Xvars]) - train['Dalc'] == 0) / float(len(train['Dalc']))\n",
    "print('Train % Correct: {:0.1f}'.format(acc * 100.))\n",
    "acc = sum(model.predict(validate[Xvars]) - validate['Dalc'] == 0) / float(len(validate['Dalc']))\n",
    "print('Validate % Correct: {:0.1f}'.format(acc * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-154-bb8c4d105495>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-154-bb8c4d105495>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model=AdaBoostClassifier()\n",
    "model.fit(train[Xvars], train['Walc'])\n",
    "\n",
    "\n",
    "acc = sum(model.predict(train[Xvars]) - train['Walc'] == 0) / float(len(train['Walc']))\n",
    "print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(validate[Xvars]) - validate['Walc'] == 0) / float(len(validate['Walc']))\n",
    "print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train % Correct: 27.9\n",
      "12 Validate % Correct: 25.0\n"
     ]
    }
   ],
   "source": [
    "model=AdaBoostClassifier()\n",
    "model.fit(train[Xvars], train['alc'])\n",
    "\n",
    "\n",
    "acc = sum(model.predict(train[Xvars]) - train['alc'] == 0) / float(len(train['alc']))\n",
    "print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(validate[Xvars]) - validate['alc'] == 0) / float(len(validate['alc']))\n",
    "print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xvars All - Train % Correct: 98.4\n",
      "Xvars All Validate % Correct: 71.9\n",
      "Xxars All Test % Correct: 64.1\n",
      "0 Train % Correct: 51.3\n",
      "0 Validate % Correct: 43.8\n",
      "1 Train % Correct: 48.2\n",
      "1 Validate % Correct: 40.6\n",
      "2 Train % Correct: 48.2\n",
      "2 Validate % Correct: 35.2\n",
      "3 Train % Correct: 52.3\n",
      "3 Validate % Correct: 43.0\n",
      "4 Train % Correct: 56.5\n",
      "4 Validate % Correct: 50.8\n",
      "5 Train % Correct: 58.1\n",
      "5 Validate % Correct: 46.9\n",
      "6 Train % Correct: 54.4\n",
      "6 Validate % Correct: 32.0\n",
      "7 Train % Correct: 50.8\n",
      "7 Validate % Correct: 46.9\n",
      "8 Train % Correct: 48.7\n",
      "8 Validate % Correct: 34.4\n",
      "9 Train % Correct: 52.6\n",
      "9 Validate % Correct: 46.1\n",
      "10 Train % Correct: 53.4\n",
      "10 Validate % Correct: 41.4\n",
      "11 Train % Correct: 54.9\n",
      "11 Validate % Correct: 44.5\n",
      "12 Train % Correct: 56.5\n",
      "12 Validate % Correct: 50.8\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier()\n",
    "model.fit(train[Xvars], train['Dalc'])\n",
    "\n",
    "acc = sum(model.predict(train[Xvars]) - train['Dalc'] == 0) / float(len(train['Dalc']))\n",
    "print 'Xvars All - Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(validate[Xvars]) - validate['Dalc'] == 0) / float(len(validate['Dalc']))\n",
    "print 'Xvars All Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(test[Xvars]) - test['Dalc'] == 0) / float(len(test['Dalc']))\n",
    "print 'Xxars All Test % Correct: {:0.1f}'.format(acc * 100.)\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    model.fit(train[X],y)\n",
    "    #print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['Dalc'] == 0) / float(len(train['Dalc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['Dalc'] == 0) / float(len(validate['Dalc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xvars All - Train % Correct: 97.9\n",
      "Xvars All Validate % Correct: 32.0\n",
      "Xxars All Test % Correct: 32.8\n",
      "0 Train % Correct: 1.8\n",
      "0 Validate % Correct: 22.7\n",
      "1 Train % Correct: 7.8\n",
      "1 Validate % Correct: 10.2\n",
      "2 Train % Correct: 4.2\n",
      "2 Validate % Correct: 15.6\n",
      "3 Train % Correct: 7.3\n",
      "3 Validate % Correct: 10.9\n",
      "4 Train % Correct: 5.2\n",
      "4 Validate % Correct: 13.3\n",
      "5 Train % Correct: 6.8\n",
      "5 Validate % Correct: 10.9\n",
      "6 Train % Correct: 4.4\n",
      "6 Validate % Correct: 15.6\n",
      "7 Train % Correct: 5.2\n",
      "7 Validate % Correct: 9.4\n",
      "8 Train % Correct: 0.8\n",
      "8 Validate % Correct: 15.6\n",
      "9 Train % Correct: 4.2\n",
      "9 Validate % Correct: 10.9\n",
      "10 Train % Correct: 8.9\n",
      "10 Validate % Correct: 18.0\n",
      "11 Train % Correct: 7.0\n",
      "11 Validate % Correct: 10.2\n",
      "12 Train % Correct: 6.0\n",
      "12 Validate % Correct: 10.2\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier()\n",
    "model.fit(train[Xvars], train['alc'])\n",
    "\n",
    "acc = sum(model.predict(train[Xvars]) - train['alc'] == 0) / float(len(train['alc']))\n",
    "print 'Xvars All - Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(validate[Xvars]) - validate['alc'] == 0) / float(len(validate['alc']))\n",
    "print 'Xvars All Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(test[Xvars]) - test['alc'] == 0) / float(len(test['alc']))\n",
    "print 'Xxars All Test % Correct: {:0.1f}'.format(acc * 100.)\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    model.fit(train[X],y)\n",
    "    #print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['alc'] == 0) / float(len(train['alc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['alc'] == 0) / float(len(validate['alc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xvars All - Train % Correct: 98.4\n",
      "Xvars All Validate % Correct: 32.0\n",
      "Xxars All Test % Correct: 30.5\n",
      "0 Train % Correct: 87.5\n",
      "0 Validate % Correct: 24.2\n",
      "1 Train % Correct: 52.3\n",
      "1 Validate % Correct: 27.3\n",
      "2 Train % Correct: 80.5\n",
      "2 Validate % Correct: 29.7\n",
      "3 Train % Correct: 52.3\n",
      "3 Validate % Correct: 29.7\n",
      "4 Train % Correct: 53.1\n",
      "4 Validate % Correct: 29.7\n",
      "5 Train % Correct: 54.2\n",
      "5 Validate % Correct: 33.6\n",
      "6 Train % Correct: 69.0\n",
      "6 Validate % Correct: 27.3\n",
      "7 Train % Correct: 57.6\n",
      "7 Validate % Correct: 33.6\n",
      "8 Train % Correct: 95.1\n",
      "8 Validate % Correct: 25.0\n",
      "9 Train % Correct: 68.0\n",
      "9 Validate % Correct: 27.3\n",
      "10 Train % Correct: 51.6\n",
      "10 Validate % Correct: 26.6\n",
      "11 Train % Correct: 54.2\n",
      "11 Validate % Correct: 32.8\n",
      "12 Train % Correct: 46.6\n",
      "12 Validate % Correct: 30.5\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier()\n",
    "model.fit(train[Xvars], train['Walc'])\n",
    "\n",
    "acc = sum(model.predict(train[Xvars]) - train['Walc'] == 0) / float(len(train['Walc']))\n",
    "print 'Xvars All - Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(validate[Xvars]) - validate['Walc'] == 0) / float(len(validate['Walc']))\n",
    "print 'Xvars All Validate % Correct: {:0.1f}'.format(acc * 100.)\n",
    "acc = sum(model.predict(test[Xvars]) - test['Walc'] == 0) / float(len(test['Walc']))\n",
    "print 'Xxars All Test % Correct: {:0.1f}'.format(acc * 100.)\n",
    "\n",
    "for i in range(13):\n",
    "    X=scopelist[i] \n",
    "    model.fit(train[X],y)\n",
    "    #print \"best score: \", model.best_score_\n",
    "    #print \"best params: \", model.best_params_\n",
    "    \n",
    "    #modeldata.append(model.best_score_)\n",
    "    #print modeldata\n",
    "    acc = sum(model.predict(train[X]) - train['Walc'] == 0) / float(len(train['Walc']))\n",
    "    print i, 'Train % Correct: {:0.1f}'.format(acc * 100.)\n",
    "    acc = sum(model.predict(validate[X]) - validate['Walc'] == 0) / float(len(validate['Walc']))\n",
    "    print i, 'Validate % Correct: {:0.1f}'.format(acc * 100.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medu</td>\n",
       "      <td>0.224713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>traveltime</td>\n",
       "      <td>0.181200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fedu</td>\n",
       "      <td>0.160568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is_address_U</td>\n",
       "      <td>0.135396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is_nursery_yes</td>\n",
       "      <td>0.123131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Features  Importance Score\n",
       "0            Medu          0.224713\n",
       "2      traveltime          0.181200\n",
       "1            Fedu          0.160568\n",
       "3    is_address_U          0.135396\n",
       "6  is_nursery_yes          0.123131"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=X\n",
    "feature_importances = model.best_estimator_.feature_importances_\n",
    "features_df = pd.DataFrame({'Features': features, 'Importance Score': feature_importances})\n",
    "features_df.sort_values('Importance Score', inplace=True, ascending=False)\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GradientBoostingClassifier\tsklearn\tGradient-boosted ensemble of decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LinearDiscriminantAnalysis\tsklearn\tClassification along the axis of maximum class separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QuadraticDiscriminantAnalysis\tsklearn\tClassification along the axis of maximum class separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LinearSVC\tsklearn\tLinear support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVC\tsklearn\tSVM with nonlinear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LogisticRegression\tsklearn\tRegress probability of being in class\n",
    "\n",
    "This would only work if I create a binary alcohol-related variable, e.g. high drinker (1) and low drinker (0)\n",
    "\n",
    "y = df['interest_level'].apply(lambda x: 1 if x == 'low' else 2 if x == 'medium' else 3)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
